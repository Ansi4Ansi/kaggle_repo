{"metadata":{"colab":{"provenance":[],"include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Ansi4Ansi/Google_colab/blob/main/ml_course/ml_b2c2024q2_simkin_HW06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"code","source":"import torch\nimport plotly.graph_objects as go\nimport numpy as np\n\ntorch.manual_seed(42)","metadata":{"id":"JvzCFL4510GI","outputId":"779b0676-34ac-481a-e6cf-55ff1f7c4141","execution":{"iopub.status.busy":"2024-05-03T03:35:51.510749Z","iopub.execute_input":"2024-05-03T03:35:51.511184Z","iopub.status.idle":"2024-05-03T03:35:55.840005Z","shell.execute_reply.started":"2024-05-03T03:35:51.511153Z","shell.execute_reply":"2024-05-03T03:35:55.838360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Оформление ДЗ**:\n\n- Выполненное ДЗ сохраните в файл ``ml_b2c2024q2_<фамилия>_HW06.ipynb`` (пример ``ml_b2c2024q2_dral_HW05.ipynb``)\n- Зарегистрироваться и залогиниться в сервисе [Everest](https://everest.distcomp.org/)\n- Перейти на страницу приложения: [BDT-grader-ML-B2C](https://everest.distcomp.org/apps/BigDataTeam/BDT-grader-ML-B2C)\n- Выбрать вкладку Submit Job (если отображается иная).\n- Выбрать в качестве “Task” значение: ``HW06:Introduction to neural networks`` (кодовое название для преподвателей: ``nn_intro``)\n- Загрузить в качестве “Task solution” файл с решением\n- В качестве Access Token указать тот, который был выслан по почте или в телеграм от аккаунта @bdt_manager\n\n**Вопросы**:\n- Свои вопросы присылайте в Телеграм.\n\n**Фидбек**:\n- Пожалуйста, оставьте свой отзыв после выполнения домашнего задания по сссылке:\n\n    https://forms.gle/iY5NRn9UfaZ344rbA","metadata":{"id":"9xWNVPoMeGa_"}},{"cell_type":"markdown","source":"# Вопросы на понимание (10%)\n\n1. Какие меры две меры ошибки мы используем для регрессии и для классификации в нейросетях?\n2. В чем задача активаций в нейросетях? Что будет происходить если их не использовать?\n3. Как можно понять что при тренировке выбран слишком высокий learning rate? А слишком низкий?\n4. У нас есть конволюционный слой с 3х3 фильтром, 32 входными каналами и 128 выходными. Какова размерность весов этого слоя? Сколько всего тренируемых параметров в этом слое?\n5. Может ли нейросеть делать правильное предсказание БЕЗ обучения? Почему/почему нет?\n\nПишите ответы внизу.","metadata":{"id":"8072bu3wd9Ir"}},{"cell_type":"markdown","source":"","metadata":{"id":"qLnyaYwgd9Is"}},{"cell_type":"markdown","source":"# Простые операции на тензорах (5%)","metadata":{"id":"cE55eP0Qd9Is"}},{"cell_type":"code","source":"# создайте тензоры x,y нормально распределенных случайных чисел размером (3, 5, 4) и (4, 7)\n\nx = torch.rand(3, 5, 4)\ny = torch.rand(4 ,7)\n# проверка\nassert x.size() == (3, 5, 4)\nassert y.size() == (4, 7)","metadata":{"id":"fdVyh0sI2vtZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# каков будет размер (измерения) произведения этих тензоров? (dot product) запишите ответ в переменную\n\ndot_product_shape = (3, 5, 7)\n\n# проверка\nassert (x @ y).size() == dot_product_shape","metadata":{"id":"XCHSVdgwmWGl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Если мы объединим 2 последних измерения тензора x в одно, каким будет размер тензора х?\n# Проверьте себя\n\nnew_x_shape = (3, 20)\nx_reshaped = x.reshape(new_x_shape)\nassert x_reshaped.size() == new_x_shape","metadata":{"id":"BpTTbgIb3coL","outputId":"ac8d380b-25c7-4c7f-e217-56de004ff9ac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Другие операции с тензорами (работает так же как numpy), работаем с тензором x\n\n# Максимальное значение в тенсоре\nprint(f\"Max value in x: {x.max()}\")\n\n# Среднее значение по второму измерению (hint: индексация с нуля)\nprint(f\"Mean value in dim 2:\\n{x.mean(axis=1)}\")","metadata":{"id":"IyDS7rpxmgN2","outputId":"7458ee08-9ad0-446c-c068-e6b3d11c933a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Автоматическая дифференциация (10%)\n\nОдна из главных фишек PyTorch и других библиотек для Deep Learning заключается в очень быстром расчете производных и градиентов.\n\nСоздайте функцию `def f(x:torch.Tensor) -> torch.Tensor:` вида\n\n$x^3 - 3x^3 - 10x^2 - 3x + 50$\n\nПосчитайте градиенты этой функции на промежутке (-2, 8) с шагом 0.1 (или меньшим, для красоты)\n\nВоспользуйтесь функцией `plot_derivative_results` для построения графика","metadata":{"id":"pjAPRCqPpPH_"}},{"cell_type":"code","source":"def f(x: torch.Tensor) -> torch.Tensor:\n    return -2*x*x*x - 10*x*x -3*x + 50\nx = torch.arange(-2, 8, 0.1)\ny = f(x)\ngrads = torch.gradient(y)\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=x, y=y, mode='lines', name='f(x)=x^3-3x^3-10x^2-50', opacity=0.7))\nfig.add_trace(go.Scatter(x=x, y = grads[0], mode='lines', name='grad(f(x))', opacity=0.7))\nfig.update_layout(title='Function and grad', width=800, height=600, xaxis_title='x', yaxis_title='f(x), grad(f(x))')\nfig.show()\n# постройте график функции f(x) и ее градиента\n\n","metadata":{"id":"uf8uqQUUrT6u","outputId":"d1e1529d-cd8f-42c6-87f7-f7bb701eb656"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"5rx40RnEVkVN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## NN in PyTorch 75%\n\nОсновная часть этого домашнего задания будет основана на создании нейросетей для датасета CIFAR10.\nМы создадим и натренируем 3 модели:\n1. Полносвязная нейросеть (Fully Connected). 2 скрытых слоя размером 512 и 128 нейронов. (25%)\n2. Сверточная нейросеть (CNN). 3 сверточных слоя с макс пуллингом и 2 полносвязных слоя. (25%)\n3. Крутая сверточная нейросеть (CNN). Архитектура как вторая, но со всеми приемами которые мы разбирали (Dropout, BatchNorm, Early Stopping, Weight Decay). (25%)\n\n### Функции для тренировки и тестирования\n\nВам нужно будет создать 4 функции, `get_dataloaders` `get_accuracy`, `train_model`, `test_model`.\n\n### Загрузка данных\n\nСначала нам надо создать функцию для загрузки данных `get_dataloaders`. Порядок действий:\n\n1. Создать base_transforms. Они переводят картинку в тензор и нормализуют его.\n2. Создать train_transforms. Они добавляют аугментации для тренировочного датасета.\n3. Загрузить тренировочный и тестовый датасеты (`torchvision.datasets.CIFAR10`).\n4. Разделить тренировочный датасет на тренировочный и валидационный. Для этого можно использовать `torch.utils.data.random_split`, 20 процентов тренировочных картинок должны попасть в валидационный датасет.\n5. Создать даталоадеры для тренировочного, валидационного и тестового датасетов. Для тренировочного датасета `shuffle=True`, для остальных `shuffle=False`.\n6. Вернуть тренировочный, валидационный и тестовый даталоадеры.\n\n\n`num_workers`, `batch_size` и `pin_memory` это параметры даталоадеров, которые могут повлиять на скорость загрузки данных. Почитайте про них в документации PyTorch.","metadata":{"id":"_zslV1Eed9Iu"}},{"cell_type":"code","source":"import torchvision\nfrom torchvision import transforms as T\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\n\n\ndef get_dataloaders(\n    transform: T.Compose = T.Compose([]),\n    batch_size: int = 256,\n    num_workers: int = 8,\n    pin_memory: bool = True,\n    val_fraction: float = 0.2,\n) -> tuple[DataLoader, DataLoader, DataLoader]:\n    base_transform = T.Compose([T.ToTensor(), T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\n    train_transform =  T.Compose([T.RandomResizedCrop(32, scale=(0.9, 1.1), antialias=True),\n                                  T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n                                  T.RandomRotation(15)])\n    transform = T.Compose([train_transform, base_transform])\n\n    # load the data\n    trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n    testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=base_transform)\n\n    val_size = int(0.2 * len(trainset))\n    train_size = len(trainset) - val_size\n    trainset, valset = torch.utils.data.random_split(trainset, [train_size, val_size])\n\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n\n    return trainloader, valloader, testloader\n\n# проверка\nbatch_size = 4\ntrainloader, valloader, testloader = get_dataloaders(batch_size=batch_size)\nimages, labels = next(iter(trainloader))\nassert images.size() == (batch_size, 3, 32, 32)\nassert labels.size() == (batch_size,)\n\n# / 2 + 0.5 - это чтобы перевести значения из диапазона [-1, 1] в [0, 1]\nplt.imshow(torchvision.utils.make_grid(images).permute(1, 2, 0).numpy() / 2 + 0.5)\n","metadata":{"id":"EUg44v3gd9Iu","outputId":"a94f3234-4eaf-4866-b993-52e08cfd93a1","execution":{"iopub.status.busy":"2024-05-03T03:38:29.625102Z","iopub.execute_input":"2024-05-03T03:38:29.626120Z","iopub.status.idle":"2024-05-03T03:38:50.073248Z","shell.execute_reply.started":"2024-05-03T03:38:29.626062Z","shell.execute_reply":"2024-05-03T03:38:50.071015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, labels = next(iter(testloader))\nplt.imshow(torchvision.utils.make_grid(images).permute(1, 2, 0).numpy() / 2 + 0.5)","metadata":{"id":"us-iG-DACIBX","outputId":"65e6510f-78ea-46ff-8b0f-4ba788eb9b76","execution":{"iopub.status.busy":"2024-05-03T03:40:06.462953Z","iopub.execute_input":"2024-05-03T03:40:06.463409Z","iopub.status.idle":"2024-05-03T03:40:06.510651Z","shell.execute_reply.started":"2024-05-03T03:40:06.463377Z","shell.execute_reply":"2024-05-03T03:40:06.508403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### `get_accuracy`\n\nФункция должна считать точность (количество правильных ответов / общее количество ответов). Пригодятся `tensor.argmax`, сравнение тензоров, `tensor.item`, `tensor.sum`.","metadata":{"id":"n_TBlxlOd9Iu"}},{"cell_type":"code","source":"def get_accuracy(outputs: torch.Tensor, labels: torch.Tensor) -> float:\n    \"\"\"\n    Outputs - предсказания модели (batch_size, n_classes)\n    Labels - истинные значения (batch_size, 1)\n    \"\"\"\n    preds = outputs.argmax(dim=1)\n    correct = (preds == labels).sum().item()\n    total = len(labels)\n    acc = correct / total\n    return acc\n\n# проверка\noutputs = torch.tensor([[0.1, 0.2, 0.7], [0.9, 0.05, 0.05], [0.2, 0.2, 0.6]])\nlabels = torch.tensor([2, 0, 2])\n\nassert get_accuracy(outputs, labels) == 1","metadata":{"id":"FBo-wCe6d9Iv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### `train_model`\n\nОсновная функция для тренировки модели. На вход подается модель, даталоадеры для тртренировочного и валидационного датасетов.\nНа ваше усмотрения можете добавить все гиперпараметры, которые считаете нужными (learning rate, num epochs, weight decay etc).\n\nПорядок действий:\n\n1. Перевести модель в режим тренировки\n2. Создать критерион для подсчета ошибки\n3. Создать оптимизатор (Adam)\n4. Переместить модель на gpu (если доступно)\n5. Создать словарь для метрик (train_loss, train_acc, val_loss, val_acc)\n6. Создать цикл для количества эпох\n7. Внутри цикла создать цикл для тренировочного и валидационного даталоадеров\n8. Внутри цикла для тренировочного даталоадера:\n    1. Обнулить градиенты\n    2. Переместить данные на gpu\n    3. Посчитать предсказания\n    4. Посчитать ошибку\n    5. Посчитать градиенты\n    6. Сделать шаг оптимизатора\n    7. Сохранить метрики\n 9. Внутри цикла для валидационного даталоадера:\n    1. Перевести модель в режим валидации\n    2. Посчитать предсказания\n    3. Посчитать ошибку\n    4. Сохранить метрики","metadata":{"id":"s3Drrhwld9Iv"}},{"cell_type":"code","source":"from torch import nn\nfrom collections import defaultdict\n\ndef get_string_output(epoch: int, metrics:dict[str, list]) -> str:\n    \"\"\"Print the epoch results\"\"\"\n    train_loss = metrics['train_loss'][epoch]\n    val_loss = metrics['val_loss'][epoch]\n    train_acc = metrics['train_acc'][epoch]\n    val_acc = metrics['val_acc'][epoch]\n    loss_string = f\"[Epoch {epoch + 1}] Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n    acc_string = f\"Train Accuracy: {train_acc * 100:.2f}%, Val Accuracy: {val_acc * 100:.2f}%\"\n    return loss_string + acc_string\n\ndef train_model(\n    model: nn.Module,\n    trainloader: DataLoader,\n    valloader: DataLoader,\n    num_epochs: int = 10,\n    lr: float = 1e-3,\n) -> dict[str, list[float]]:\n    metrics = dict(train_loss=[], val_loss=[], train_acc=[], val_acc=[])\n    # move model to GPU\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    # init loss, optimiser\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n    for epoch in range(num_epochs):\n        # save metrics from each batch to calculate mean per epoch\n        epoch_metrics = defaultdict(list)\n        model.train()\n        # Train loop\n        for data in trainloader:\n            inputs, labels = data[0].to(device), data[1].to(device)\n            optimizer.zero_grad()\n            outputs = model.forward(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            acc = get_accuracy(outputs, labels)\n            epoch_metrics['train_acc'].append(acc)\n            epoch_metrics['train_loss'].append(loss.item())\n\n        # Validation loop\n        model.eval()\n        with torch.no_grad():\n            for data in valloader:\n                inputs, labels = data[0].to(device), data[1].to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                acc = get_accuracy(outputs, labels)\n                epoch_metrics['val_acc'].append(acc)\n                epoch_metrics['val_loss'].append(loss.item())\n        # Housekeeping\n        for k,v in epoch_metrics.items():\n            metrics[k].append(np.mean(v))\n        print(get_string_output(epoch, metrics))\n    return metrics","metadata":{"id":"l8Pi4SNNd9Iv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### `test_model`\n\nФункция для тестирования модели. На вход подается модель и даталоадер для тестового датасета.\n\nПорядок действий похож на `train_model`, но с некоторыми отличиями:\n\n* Не нужно обновлять веса модели\n* Не нужно считать градиенты\n* Соответсвенно, не нужен оптимизатор\n* Нет цикла для эпохов\n* Только один цикл для даталоадера\n  \nФункция должна вернуть точность и лосс на тестовом датасете.","metadata":{"id":"lzD8etTjd9Iv"}},{"cell_type":"code","source":"def test_model(model: nn.Module, testloader: DataLoader) -> tuple[float, float]:\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n    acc = []\n    loss_report = []\n    criterion = nn.CrossEntropyLoss()\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data[0].to(device), data[1].to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            acc.append(get_accuracy(outputs, labels))\n            loss_report.append(loss.item())\n    return np.mean(loss_report), np.mean(acc)","metadata":{"id":"0rU_fmzPd9Iv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Проверка функций\n\nПосле этого можно проверить функции `train_model` и `test_model`.\nДля этого у вас есть модель `BadModel` (что она делает?).\n\nПопробуйте \"натренировать\" эту модель на одной эпохе и проверить работоспособность функций.","metadata":{"id":"ZkuefNx0d9Iv"}},{"cell_type":"code","source":"class BadModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer = nn.Linear(1, 10)\n\n    def forward(self, x):\n        xmean = x.mean(dim=(1, 2, 3)).unsqueeze(1)\n        x = self.layer(xmean)\n        return x\n\n\ntrainloader, valloader, testloader = get_dataloaders()\nbad_model = BadModel()\ntrain_metrics = train_model(bad_model, trainloader, valloader, num_epochs=5)\ntest_loss, test_acc = test_model(bad_model, testloader)\nprint(f\"Test Loss: {test_loss:.4f}, Test acc: {test_acc * 100:.2f}%\")","metadata":{"id":"_03dDEcdd9Iv","outputId":"81d33a3f-bd7b-45a7-bd13-2f93d805bb72"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Создание моделей\n\nЕсли все прошло успешно, можно переходить к созданию моделей.\n\n#### Полносвязная нейросеть\n\nПараметры - 2 скрытых слоя размером 512 и 128 нейронов. Активация - ReLU.\n\nИспользуйте `nn.Linear`, `torch.relu`, `tensor.flatten` или `tensor.view`.\n\nНатренируйте модель на 30 эпохах. Посмотрите на точность на тренировочном, валидационном и тестовом датасетах.\n\nПостройте график лосса и точности на тренировочном и валидационном датасетах.\n\n**Вопросы:**\n\n1. Какая точность на тестовом датасете?\n2. Как быстро сходится модель?\n3. Происходит ли переобучение?\n4. Если да, то в какой момент?","metadata":{"id":"KTCpFViMd9Iv"}},{"cell_type":"code","source":"class SimpleNN(nn.Module):\n    def __init__(self, image_size : int = 32, channels: int = 3): #CIFAR10 - image size 32x32x3\n        super().__init__()\n\n        self.fc1 = nn.Linear(image_size * image_size * channels, 512)\n        self.fc2 = nn.Linear(512, 128)\n        self.fc3 = nn.Linear(128, 10)\n\n    def forward(self, x:torch.Tensor) -> torch.Tensor:\n        x = x.flatten(1, -1)\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\ntrainloader, valloader, testloader = get_dataloaders()\nmodel = SimpleNN()\ntrain_metrics_simple = train_model(model, trainloader, valloader, num_epochs=30)\ntest_loss_simple, test_acc_simple = test_model(model, testloader)\nprint(f\"Test Loss: {test_loss_simple:.4f}, Test acc: {test_acc_simple * 100:.2f}%\")","metadata":{"id":"aGisgeYEsRHR","outputId":"18f06f06-0baa-4ce0-9020-bf13676d58b1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss_simple, test_acc_simple = test_model(model, testloader)\nprint(f\"Test Loss: {test_loss_simple:.4f}, Test acc: {test_acc_simple * 100:.2f}%\")","metadata":{"id":"w1jiBY5sQVWS","outputId":"e17f1f82-b782-47cb-88ac-f50e3a6fd07c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_accuracy_loss(p_train_metrics : defaultdict(list)) :\n  fig = go.Figure()\n  x = x=torch.arange(1, len(p_train_metrics['train_acc']))\n  fig.add_trace(go.Scatter(x=x, y=p_train_metrics['train_acc'], mode='lines', name='Train accuracy', opacity=0.7))\n  fig.add_trace(go.Scatter(x=x, y=p_train_metrics['val_acc'], mode='lines', name='Validation accuracy', opacity=0.7))\n  fig.add_trace(go.Scatter(x=x, y=p_train_metrics['train_loss'], mode='lines', name='Train loss', opacity=0.7))\n  fig.add_trace(go.Scatter(x=x, y=p_train_metrics['val_loss'], mode='lines', name='Validation loss', opacity=0.7))\n  fig.update_layout(title='Accuracy & loss', width=800, height=600, xaxis_title='Epoch', yaxis_title='Accuracy & loss')\n  fig.show()\n\nplot_accuracy_loss(train_metrics_simple)","metadata":{"id":"GuvSz0LTVy1T","outputId":"233a8311-6909-4a2d-e24f-8c12cc1a9383"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Yw7GHbF8WliD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Сверточная нейросеть\n\nПараметры - 3 сверточных слоя с макс пуллингом и 2 полносвязных слоя. Активацонная функция тоже ReLU.\n\nИспользуйте `nn.Conv2d`, `nn.MaxPool2d`, остальные функции как в предыдущей модели.\n\nДля сверточных слоев используйте `kernel_size=3`, `padding=1`, `stride=1`. Для макс пуллинга `kernel_size=2`, `stride=2`.\n\nНатренируйте модель на 30 эпохах. Посмотрите на точность на тренировочном, валидационном и тестовом датасетах.\n\nПостройте график лосса и точности на тренировочном и валидационном датасетах.\n\n**Вопросы:**\n\n1. Какая точность на тестовом датасете?\n2. Как быстро сходится модель?\n3. Происходит ли переобучение?\n4. Если да, то в какой момент?\n5. Какая модель лучше, полносвязная или сверточная?","metadata":{"id":"pnKh9kyHd9Iv"}},{"cell_type":"code","source":"class SimpleCNN(nn.Module):\n    def __init__(self, image_size : int = 32, channels: int = 3):\n        super().__init__()\n        self.image_size = image_size\n        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 128 * 4, 512)\n\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 10)\n\n    def forward(self, x:torch.Tensor) -> torch.Tensor:\n        x = self.pool(torch.relu(self.conv1(x)))\n        x = self.pool(torch.relu(self.conv2(x)))\n        x = self.pool(torch.relu(self.conv3(x)))\n        x = x.flatten(1, -1)\n        #x = x.view(-1, 128 * 128 * 32)\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\ntrainloader, valloader, testloader = get_dataloaders()\nmodel = SimpleCNN()\ntrain_metrics_simple_cnn = train_model(model, trainloader, valloader, num_epochs=30)\ntest_loss_simple_cnn, test_acc_simple_cnn = test_model(model, testloader)\nprint(f\"Test Loss: {test_loss_simple_cnn:.4f}, Test acc: {test_acc_simple_cnn * 100:.2f}%\")","metadata":{"id":"6QL655Tpd9Iv","outputId":"be694f2d-db88-47b8-8e44-07b71f3a81fe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accuracy_loss(train_metrics_simple_cnn)","metadata":{"id":"5-8azfkaCIBb","outputId":"c7c0040e-4be4-4778-90a5-7e167a07841a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Крутая сверточная нейросеть\n\nЗадание аналогично предыдущему, но добавьте все приемы, которые мы разбирали (Dropout, BatchNorm, Early Stopping, Weight Decay, Data Augmentation).\nВозможно Вам придется переписать функции `get_dataloaders`, `train_model` и `test_model`.\n\nЦель - точность в 80% на тестовом датасете. Ограничение в 30 эпох.","metadata":{"id":"I4symsXPd9Iv"}},{"cell_type":"markdown","source":"","metadata":{"id":"DHfJFmLCd9Iw"}},{"cell_type":"code","source":"def train_model_cnn(\n    model: nn.Module,\n    trainloader: DataLoader,\n    valloader: DataLoader,\n    num_epochs: int = 10,\n    learning_rate: float = 1e-3,\n    weight_decay = 1e-2,\n) -> dict[str, list[float]]:\n    metrics = dict(train_loss=[], val_loss=[], train_acc=[], val_acc=[])\n    # move model to GPU\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    # init loss, optimiser\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n\n    learning_rate_decay_factor = 0.96\n    learning_rate_decay_step = 3\n    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=learning_rate_decay_factor, last_epoch=-1)\n\n    for epoch in range(num_epochs):\n        # save metrics from each batch to calculate mean per epoch\n        epoch_metrics = defaultdict(list)\n        model.train()\n        # Train loop\n        for data in trainloader:\n            inputs, labels = data[0].to(device), data[1].to(device)\n            optimizer.zero_grad()\n            outputs = model.forward(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            acc = get_accuracy(outputs, labels)\n            epoch_metrics['train_acc'].append(acc)\n            epoch_metrics['train_loss'].append(loss.item())\n\n        if epoch % learning_rate_decay_step == 0:\n            lr_scheduler.step()\n        print(f'Epoch {epoch} learning rate {lr_scheduler.get_last_lr()}')\n\n        # Validation loop\n        model.eval()\n        with torch.no_grad():\n            for data in valloader:\n                inputs, labels = data[0].to(device), data[1].to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                acc = get_accuracy(outputs, labels)\n                epoch_metrics['val_acc'].append(acc)\n                epoch_metrics['val_loss'].append(loss.item())\n        # Housekeeping\n        for k,v in epoch_metrics.items():\n            metrics[k].append(np.mean(v))\n        print(get_string_output(epoch, metrics))\n    return metrics","metadata":{"id":"HaIW6DBBa3Pk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ModifiedCNN(nn.Module):\n    def __init__(self, image_size : int = 32, channels: int = 3, p_dropout: float = 0.25):\n        super().__init__()\n        self.image_size = image_size\n        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n        self.batch32 = nn.BatchNorm2d(32)\n        self.batch64 = nn.BatchNorm2d(64)\n        self.batch128 = nn.BatchNorm2d(128)\n        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 10)\n\n        self.dropout = nn.Dropout(p = p_dropout)\n\n    def forward(self, x:torch.Tensor) -> torch.Tensor:\n        x = self.pool(torch.relu(self.batch32(self.conv1(x))))\n        x = self.dropout(x)\n        x = self.pool(torch.relu(self.batch64(self.conv2(x))))\n        x = self.dropout(x)\n        x = self.pool(torch.relu(self.batch128(self.conv3(x))))\n        x = self.dropout(x)\n        x = x.flatten(1, -1)\n        #x = x.view(-1, 128 * 128 * 32)\n        x = torch.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = torch.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = self.fc3(x)\n        return x\n\n\ntrainloader, valloader, testloader = get_dataloaders()\nmodel = ModifiedCNN(p_dropout = 0.2)\ntrain_metrics_modified_cnn = train_model_cnn(model, trainloader, valloader, num_epochs=30)\ntest_loss_modified_cnn, test_acc_modified_cnn = test_model(model, testloader)\nprint(f\"Test Loss: {test_loss_modified_cnn:.4f}, Test acc: {test_acc_modified_cnn * 100:.2f}%\")","metadata":{"id":"FXMesNkNsGGd","outputId":"2cf357bd-78b3-4fb9-8013-a8feb7e48540"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accuracy_loss(train_metrics_modified_cnn)","metadata":{"id":"4aOHH9EQFGYW","outputId":"d1145ad5-4f4f-4722-b3be-b951b486b822"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure()\nx = x=torch.arange(1, len(train_metrics_simple['train_acc']))\nfig.add_trace(go.Scatter(x=x, y=train_metrics_simple['train_acc'], mode='lines', name='Train accuracy simple', opacity=0.7))\nfig.add_trace(go.Scatter(x=x, y=train_metrics_simple['val_acc'], mode='lines', name='Validation accuracy simple', opacity=0.7))\nfig.add_trace(go.Scatter(x=x, y=train_metrics_simple_cnn['train_acc'], mode='lines', name='Train accuracy CNN', opacity=0.7))\nfig.add_trace(go.Scatter(x=x, y=train_metrics_simple_cnn['val_acc'], mode='lines', name='Validation accuracy CNN', opacity=0.7))\nfig.add_trace(go.Scatter(x=x, y=train_metrics_modified_cnn['train_acc'], mode='lines', name='Train accuracy mod CNN', opacity=0.7))\nfig.add_trace(go.Scatter(x=x, y=train_metrics_modified_cnn['val_acc'], mode='lines', name='Validation accuracy mod CNN', opacity=0.7))\nfig.update_layout(title='Accuracy ', width=800, height=600, xaxis_title='Epoch', yaxis_title='Accuracy')\nfig.show()","metadata":{"id":"X0iBCSl1I2hR","outputId":"ed93ba03-b412-4308-ddd5-3d060a4b1554"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Решил ДЗ - дай обратную связь ;)\n\nНадеемся, было интересно и полезно.\n\nПожалуйста, оставьте обратную связь по этому домашнему заданию: https://forms.gle/iY5NRn9UfaZ344rbA","metadata":{"id":"ZQ1WSwJNerSj"}}]}