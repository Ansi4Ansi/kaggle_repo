{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"name":"lesson8_part2_PCA.ipynb","toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[],"include_colab_link":true},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Ansi4Ansi/Google_colab/blob/main/ML_B2C_2024_Q2_%7C_HW09_ML_unsupervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"# Homework #07: Unsupervised","metadata":{"id":"i6FFQbU33qyM"}},{"cell_type":"markdown","source":"<span style=\"color: red; font-size: 14pt\">Deadline: 16.06.2019, 23:59</span>","metadata":{"id":"1gl-cPkH3qyQ"}},{"cell_type":"markdown","source":"**Оформление ДЗ**:\n\n- Выполненное ДЗ сохраните в файл ``ml_b2c2024q2_<Surname>_<Name>_HW#.ipynb``\n  \n  (пример ``ml_b2c2024q2__Dral_Alexey_HW01.ipynb``)\n- Зарегистрироваться и залогиниться в сервисе [Everest](https://everest.distcomp.org/)\n- Перейти на страницу приложения: [BDT-grader-ML-B2C](https://everest.distcomp.org/apps/BigDataTeam/BDT-grader-ML-B2C)\n- Выбрать вкладку Submit Job (если отображается иная).\n- Выбрать в качестве “Task” значение: ``HW09:unsupervised`` (кодовое название для преподвателей: ``ml.unsupervised``)\n- Загрузить в качестве “Task solution” файл с решением\n- В качестве Access Token указать тот, который был выслан по почте или в телеграм от аккаунта @bdt_manager\n\n**Дополнительные ссылки**\n- Настройка локального окружения: https://github.com/big-data-team/ml-course\n- Датасеты UCI: https://archive.ics.uci.edu/\n\n**Вопросы**:\n- Свои вопросы присылайте в Телеграм.\n\n**Фидбек**:\n- Пожалуйста, оставьте свой отзыв после выполнения домашнего задания по сссылке:\n\n    https://forms.gle/Pny6dhdmhZZRNNQs5","metadata":{"id":"AYA7cnpy3qyR"}},{"cell_type":"markdown","source":"### Вопросы на понимание","metadata":{"id":"fzX9RE983qyS"}},{"cell_type":"markdown","source":"1. Можно ли использовать категориальные признаки для алгоритма K-Means? Если можно, то как? Если нет, то почему?\n2. В чем разница между K-Means и K-Medoids?\n3. Кто лучше справится с данными с шумом: K-Means или DBSCAN?\n4. При каком объеме выборки становится невозможно найти глобальный оптимальный алгоритмов кластеризации? Приведите расчеты / оценки.\n5. Какую величину выражают собственные значения ковариационной матрицы X.T?\n6. Что такое Proportion of Variance Explained?\n7. PCA и SVD это одно и тоже или разные вещи?\n8. Какая оптимизационная задача решается в t-SNE?\n9. Какие алгоритмы из PCA, t-SNE являются детерминированными, а какие нет.","metadata":{"id":"nPQ7CYsR3qyT"}},{"cell_type":"markdown","source":"<ваши ответы - здесь>","metadata":{"id":"gdjlzhaT3qyT"}},{"cell_type":"markdown","source":"## Полезные import'ы","metadata":{"id":"HmB_aiPT3qyU"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nprint(sys.version)","metadata":{"id":"EkAy4Izj3qyU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn\nprint(sklearn.__version__)","metadata":{"id":"nzWGaZ8Y3qyV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\n%matplotlib inline","metadata":{"id":"zfvmo7XR3qyV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition  import PCA\nfrom sklearn.datasets import load_digits","metadata":{"id":"WdbBkCg13qyV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Data Compression (30 %)\n\nPCA can also be used for data compression. We are going to experiment with amount of principal components necessary to recover original image with high quality.","metadata":{"id":"rxbHZjSN3qyW"}},{"cell_type":"code","source":"digits = load_digits()","metadata":{"id":"IDQBurPK3qyW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = digits.data\nY = digits.target","metadata":{"id":"aUzljXQW3qyW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"id":"gLkwqHI63qyW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_image_id = 15\n\nplt.figure(figsize=(4,2))\nplt.imshow(X[target_image_id].reshape((8, 8)), cmap='binary')\nplt.xticks([])\nplt.yticks([])\nplt.title('Source image')\n\nfig, axes = plt.subplots(8, 8, figsize=(10, 10))\nfig.subplots_adjust(hspace=0.1, wspace=0.1)\n\nfor index, ax in enumerate(axes.flat):\n    n_components = index + 1\n    # Task: train PCA transformer with n_components and get reduced\n    # image with id `target_image_id` plotted in high-dimensional\n    # feature space\n    # hint: take special care about shape of observations\n\n    <your code>\n    recovered_image = <your code>\n\n    ax.imshow(recovered_image.reshape((8, 8)), cmap='binary')\n    ax.text(0.95, 0.05, 'n = {0}'.format(n_components), ha='right',\n            transform=ax.transAxes, color='red')\n    ax.set_xticks([])\n    ax.set_yticks([])","metadata":{"id":"4gMSOpB33qyW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### How many PCA components do you need to decompress image with quite a good quality?","metadata":{"id":"XIr4T5H33qyW"}},{"cell_type":"code","source":"# your answer here","metadata":{"id":"uGsU1ky_3qyW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### How many components do you need to explain 90% of variance?","metadata":{"id":"TfVTpug53qyW"}},{"cell_type":"code","source":"# train PCA transformer and get the amount of components from the transformer\n# <your code>\npca_pve90_n_components = <save the found amount components into this variable>\nprint(f\"We need {pca_pve90_n_components} components to explain 90% of variance\")","metadata":{"id":"ukGZyNcb3qyX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot Total explained variance to support your statement","metadata":{"id":"dH5RgcSL3qyX"}},{"cell_type":"code","source":"pca = PCA().fit(X)\n\nplt.figure(figsize=(10,7))\n# plot cumulative PVE for each value of [1..n_components]\n# hint: see np.cumsum\nplt.plot(<your code>, color='black', lw=2)\n\n# plot horizontal line for PVE 90%, set \"red\" color\nplt.<your code>\n# plot vertical line for chosen pca_pve90_n_components, set \"blue\" color\nplt.<your code, use `pca_pve90_n_components` variable>\n\n\nplt.xlim(0, X.shape[1])\nplt.yticks(np.arange(0, 1.1, 0.1))\nplt.xlabel('Number of components')\nplt.ylabel('Total explained variance');","metadata":{"id":"pLvZnBg33qyX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Labeled Faces in the Wild (LFW) (30%)","metadata":{"id":"AIoX4ttT3qyX"}},{"cell_type":"markdown","source":"### Preprocessing","metadata":{"id":"l9GSdEv63qyX"}},{"cell_type":"code","source":"import PIL\nprint(PIL.__version__)","metadata":{"id":"8svrorDO3qyX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import datasets","metadata":{"id":"cu-jjRnq3qyX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nlfw_people = datasets.fetch_lfw_people(\n    min_faces_per_person=50,\n    resize=0.4,\n)","metadata":{"id":"xX9RLCuk3qyX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\n    f'{lfw_people.data.shape[0]} objects, '\n    + f'{lfw_people.data.shape[1]} features, '\n    + f'{len(lfw_people.target_names)} classes'\n)","metadata":{"id":"ATOfXZIN3qyX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show label distribution\nfor person_index, name in enumerate(lfw_people.target_names):\n    print(f\"{name:20}: {(lfw_people.target == person_index).sum():3} photos.\")","metadata":{"id":"Jw8v7lNJ3qyX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(8, 6))\n\nfor subplot_index in range(15):\n    ax = fig.add_subplot(3, 5, subplot_index + 1, xticks=[], yticks=[])\n    ax.imshow(lfw_people.images[subplot_index], cmap='bone')","metadata":{"id":"Ke7jSV5B3qyX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split dataset into train and test in ratio 75:25\nX_train, X_test, y_train, y_test = <your code>\n\nprint('Train size:', X_train.shape[0], 'Test size:', X_test.shape[0])","metadata":{"id":"inq-itpf3qyX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train PCA on \"train\" dataset with 100 components\n<your code>","metadata":{"id":"9-eg8cW73qyY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print how many PVE explained by all 100 n_components\n<your code>","metadata":{"id":"PuDfKoNk3qyY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot \"Total explained variance\" over n_components in range [0,100]\nplt.figure(figsize=(10,7))\n<your code>","metadata":{"id":"DrW7o2eo3qyY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the first 30 Principal Components in the original feature space\n# note: use grid 3 (rows) x 10 (columns)\n# note: consider face shape 50x37\nfig = plt.figure(figsize=(16, 6))\n<your code>","metadata":{"id":"250lTa0J3qyY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### What can you say about principle components? Does any of the principal components help to find feature dimension such as \"nose\", \"lightning\" or something else?","metadata":{"id":"BzgdaZbv3qyY"}},{"cell_type":"code","source":"# your answer","metadata":{"id":"cgwtEqCV3qyY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make some fun","metadata":{"id":"rCYdwyFy3qyY"}},{"cell_type":"code","source":"# What is the average face in the \"wild\"?\nX_train.shape","metadata":{"id":"BoO2O4eA3qyY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Average all features with np.mean\nplt.imshow(X_train.mean(axis=0).reshape(50, 37), cmap='bone')\nplt.xticks([])\nplt.yticks([]);","metadata":{"id":"jDQ5rFO_3qyc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Occasionally PCA does it for you already\nplt.imshow(pca.mean_.reshape((50, 37)), cmap='bone')\nplt.xticks([])\nplt.yticks([]);","metadata":{"id":"wEPcz9lu3qyc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Pipeline optimization (40%)","metadata":{"id":"Q7aDGA5f3qyc"}},{"cell_type":"code","source":"# Our goal is to speed-up calculations without loosing much of a quality with the\n# help of dimensionality reduction algorithm","metadata":{"id":"LD5kiqhd3qyd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.svm import LinearSVC","metadata":{"id":"Wg_yQvxC3qyd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# Train LinearSVC on X_train, y_train with cv=5, set number of iteration to 10^4\ncv_score = cross_val_score(<your code>)\nprint(f\"{cv_score.mean():.3f}, {cv_score.std():.3f}\")","metadata":{"id":"kOIKyZo13qyd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# you should see warnings \"Liblinear failed to converge, increase the number of iterations\"\n# instead of doing this, let us add scaling to the pipeline, it helps optimization algorithms\n\npipeline = Pipeline(<your code>)\ncv_score = cross_val_score(<your code>)\nprint(f\"{cv_score.mean():.3f}, {cv_score.std():.3f}\")","metadata":{"id":"8Sl3eAkn3qyd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now you should be able to get better quality and to get rid of the warning\n# to save time necessary to train the model\n# copy time from the previous cell and cast to seconds\nwall_time_in_seconds = <wall time from the previous cell execution>\noriginal_SVM_quality = cv_score.mean()","metadata":{"id":"wbyib32O3qyd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# our goal is to speed-up calculations by 100x without significant decrease in quality (let's say 1-2%)\n# I heard that PCA might be of a great help\n# add the first step (PCA with n_components = 10) to our pipeline:\n\npipeline = Pipeline(<your code>)\ncv_score = cross_val_score(<your code>)\nprint(f\"{cv_score.mean():.3f}, {cv_score.std():.3f}\")","metadata":{"id":"VvEf_xw53qyd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Wow, do you see how fast is it?\n# Let us try to find the appropriate amount of components\n# with the help of GridSearchCV\npipeline = Pipeline(<your code>)\n\nparam_grid = {\n    'pca__n_components': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500],\n}\n\ngrid_search = GridSearchCV(\n    pipeline, param_grid, iid=False, cv=5,\n    return_train_score=False\n)","metadata":{"id":"HrceV0m73qyd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# Let's grid_search do all the magic for us:\ngrid_search.<your magic code>\nprint(f\"Best parameter (CV score={grid_search.best_score_:0.3f}): {grid_search.best_params_}\")","metadata":{"id":"nrNZSW9V3qyd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Analyse and visualize results","metadata":{"id":"dmFVxgoN3qyd"}},{"cell_type":"code","source":"# show CV-results\ncv_results_df = pd.DataFrame(grid_search.cv_results_)\ncv_results_df","metadata":{"id":"9FinEIPU3qyd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualize the best quality pipeline","metadata":{"id":"K34442FW3qyd"}},{"cell_type":"code","source":"pca = PCA().fit(X_train)\n\nfig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(6, 6))\nax0.plot(pca.explained_variance_ratio_, linewidth=2)\nax0.set_ylabel('PCA explained variance')\nax0.axvline(\n    grid_search.best_estimator_.named_steps['pca'].n_components,\n    linestyle=':', label='n_components chosen'\n)\nax0.legend(prop=dict(size=12))\n\ncv_results_df.plot(\n    x='param_pca__n_components', y='mean_test_score', yerr='std_test_score',\n    legend=True, ax=ax1\n)\nax1.axvline(\n    grid_search.best_estimator_.named_steps['pca'].n_components,\n    linestyle=':', label='n_components chosen'\n)\nax1.set_ylabel('Classification accuracy (CV=5)')\nax1.set_xlabel('n_components')\nax1.set_xlim(left=0)\n\nplt.tight_layout();","metadata":{"id":"AfMChwyn3qye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot \"time\" spent to fit the models\ncv_results_df.plot(\n    x='param_pca__n_components', y='mean_fit_time',\n    legend=True\n)\nplt.title(\"Fit time in seconds\");","metadata":{"id":"QxwnYblW3qye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compared to the original `wall_time_in_seconds` what is speed-up factor?\n# Compared to the original `original_SVM_quality` what is the quality of best-pipeline?\n# Which model are you going to use in production?\n# How much of the variance explained was enough to achieve such a good quality?","metadata":{"id":"nE38yNTb3qye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"<your answer>","metadata":{"id":"cvNKX6Ie3qye"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Validate quality of the best model on hold-out dataset","metadata":{"id":"NY-q7jol3qye"}},{"cell_type":"code","source":"y_pred = grid_search.best_estimator_.predict(X_test)","metadata":{"id":"ZVpaOaIc3qye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n\nprint(\"Accuracy: %f\" % accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred, target_names=lfw_people.target_names))","metadata":{"id":"6q1J6hLQ3qye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"M = confusion_matrix(y_test, y_pred)\n# normalize confusion matrix over y_test rows\nM_normalized = M.astype('float') / M.sum(axis=1)[:, np.newaxis]","metadata":{"id":"IDGU-kki3qye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nim = plt.imshow(M_normalized, cmap='Greens')\nplt.colorbar(im, shrink=0.7)\ntick_marks = np.arange(len(lfw_people.target_names))\nplt.xticks(tick_marks - 0.5, lfw_people.target_names, rotation=45)\nplt.yticks(tick_marks, lfw_people.target_names)\nplt.tight_layout()\nplt.xlabel('Predicted person')\nplt.ylabel('True person')\nplt.title('Normalized confusion matrix');","metadata":{"id":"dUr_tol03qye"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Q&A:\n1. Which person was easy to classify?\n2. Which person was difficult to classify?\n3. What is the most common error? Which person was frequenlty misclassified by another one?","metadata":{"id":"dFgVkq8X3qyf"}},{"cell_type":"code","source":"# your answer","metadata":{"id":"yYdjehI-3qyf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bonus","metadata":{"id":"EpjS1WTS3qyf"}},{"cell_type":"markdown","source":"According to the article \"Pinto, Nicolas, James J. DiCarlo, and David D. Cox. \"How far can you get with a modern face recognition test set using only simple features?.\" 2009 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2009.\" http://www.coxlab.org/pdfs/pinto-dicarlo-cox-cvpr-2009-mkl.pdf\n    \nthey were able to get the quality 79.35%. Can you do better?","metadata":{"id":"cgAb6lI73qyf"}},{"cell_type":"code","source":"<your code and comments>","metadata":{"id":"W0-yC6yQ3qyf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Useful links\n- [Eigenface](https://en.wikipedia.org/wiki/Eigenface)\n- [sklearn.decomposition](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition)\n- [LIBLinear home page](https://www.csie.ntu.edu.tw/~cjlin/liblinear/)\n- [LIBLinear FAQ](https://www.csie.ntu.edu.tw/~cjlin/liblinear/FAQ.html)","metadata":{"id":"37AmlAvY3qyf"}},{"cell_type":"markdown","source":"Надеемся, было интересно и полезно.\n\nПожалуйста, оставьте обратную связь по этому домашнему заданию: https://forms.gle/Pny6dhdmhZZRNNQs5.","metadata":{"id":"0C-ZEok33qyf"}}]}