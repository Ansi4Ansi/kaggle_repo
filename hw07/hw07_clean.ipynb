{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install accelerate==0.25.0\n#!pip install bertopic==0.15.0\n#!pip install datasets==2.14.4\n#!pip install faiss-cpu==1.7.4\n#!pip install langchain==0.0.348\n#!pip install langchainhub==0.1.14\n#!pip install sentence-transformers==2.2.2\n#!pip install sentencepiece==0.1.99\n#!pip install transformers==4.24.0\n!pip install wandb --upgrade","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:30:24.155245Z","iopub.execute_input":"2024-05-20T07:30:24.155520Z","iopub.status.idle":"2024-05-20T07:30:37.322319Z","shell.execute_reply.started":"2024-05-20T07:30:24.155495Z","shell.execute_reply":"2024-05-20T07:30:37.321377Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport transformers\nimport typing as tp\nimport wandb\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, PreTrainedTokenizer, PreTrainedTokenizerFast\nfrom datasets import load_dataset\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom tqdm import tqdm\n\nfrom sklearn.metrics import recall_score, f1_score, precision_score\nfrom pprint import pprint\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ntorch.manual_seed(42)\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-20T07:30:46.327262Z","iopub.execute_input":"2024-05-20T07:30:46.328217Z","iopub.status.idle":"2024-05-20T07:30:53.792904Z","shell.execute_reply.started":"2024-05-20T07:30:46.328169Z","shell.execute_reply":"2024-05-20T07:30:53.792004Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x79215b46ad90>"},"metadata":{}}]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    \"\"\"\n    This class designs logic to retrieve data from a custom dataset.\n    According to pytorch Dataset conception any map style dataset\n    should implement at least __len__ and __getitem__ methods.\n    \"\"\"\n\n    def __init__(\n        self, texts, labels, tokenizer, max_length\n    ) -> None:\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self) -> int:\n        \"\"\"\n        returns number of rows in data\n        \"\"\"\n        return len(self.texts)\n\n    def __getitem__(self, idx: int) -> tp.Dict[str, tp.Any]:\n        \"\"\"\n        retrieves data for single index.\n        may include data processing and transformations.\n        E.g. augmenting data or tokenizing it.\n        returns dict with keys \"input_ids\", \"label\" and probably some more metadata (you decide whethere you need something more here)\n        \"\"\"\n        text = self.texts[idx]\n        label = self.labels[idx]\n\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            'input_ids': encoding['input_ids'].squeeze(),\n            'attention_mask': encoding['attention_mask'].squeeze(),\n            'label': torch.tensor(label, dtype=torch.long)\n        }\n\n\nclass ModelTrainer:\n    \"\"\"\n    This class implements logic run an experiemnt with a provided transformers classification model.\n    It incudes following components:\n    - load data\n    - load and configure a model and its artifacts\n    - train model\n    - validate model\n    - save model\n    - compue metrics\n    - run_experiment (as the man entrypoint to execute all flow)\n\n    Attention: current module intentionally doesnt support model inference or model serving.\n    It is a good practice to separate train/inference classes otherwise it is hard to maintain it all.\n\n    \"\"\"\n\n    def __init__(self, model_name: str, dataset_name: str, sample: int =-1, random_state: int = 42) -> None:\n        self.model_name = model_name\n        self.dataset_name = dataset_name\n        \n        \n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        \n        self.model = transformers.AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=2)\n        \n        self.tokenizer = transformers.AutoTokenizer.from_pretrained(self.model_name)\n        self.model_config = transformers.AutoConfig.from_pretrained(self.model_name)\n        self.sample = sample\n        self.random_state = random_state\n\n    def configure_optimizer(self, optimizer, params: tp.Dict) -> None:\n        \"\"\"\n        adds a self.optimizer attribute with a chosen optimizer and its params.\n        \"\"\"\n\n        self.optimizer = optimizer\n        for key, value in params.items():\n            for g in self.optimizer.param_groups:\n                g[key] = value\n\n    def configure_scheduler(self, scheduler) -> None:\n        \"\"\"\n        adds a self.scheduler attribute with a chosen scheduler (e.g. ReduceLROnPlateau).\n        \"\"\"\n\n        self.scheduler = scheduler\n\n    def apply_data_parallel(self) -> None:\n        \"\"\"\n        checks number of available cuda devices,\n        if number of GPUs is > 1, moves self.model to a DataParallel state for faster training.\n        \"\"\"\n        \n        if torch.cuda.device_count()>1:\n            self.model = torch.nn.DataParallel(self.model, device_ids=list(range(torch.cuda.device_count())))\n\n    def load_data(self, filename: str, split: str) -> pd.DataFrame:\n        \"\"\"\n        uses Datasets library to load a dataset, takes as input dataset name (e.g. \"imdb\")\n        and a split. Loads data into pandas.\n        \"\"\"\n        \n        ds = load_dataset(filename, split = split)\n        if self.sample > 0 :\n            return ds.to_pandas().sample(n = self.sample, random_state = self.random_state)\n        else:\n            return ds.to_pandas()\n        \n    def train(self, dataset: CustomDataset) -> None:\n        \n        # заглушка, если шедулер и оптимайзер не инцииализированы\n        self.optimizer = self.optimizer or AdamW(self.model.parameters(), lr = 1e-3)\n        self.scheduler = self.scheduler or ExponentialLR(optimizer=self.optimizer, gamma=0.9, last_epoch=-1)\n        \n        train_loader = DataLoader(dataset, batch_size=8, shuffle=False)\n        \n        self.model.to(self.device)\n        \n        correct = 0\n        self.model.train()\n        for epoch in tqdm(range(wandb.config[\"epochs\"])):\n            total_loss = 0.0\n\n            for batch in train_loader:\n                input_ids = batch['input_ids'].to(self.device)\n                attention_mask = batch['attention_mask'].to(self.device)\n                labels = batch['label'].to(self.device)\n\n                self.optimizer.zero_grad()\n                outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n                loss = outputs.loss\n                loss.backward()\n                self.optimizer.step()\n                \n                if epoch % wandb.config[\"learning_rate_decay_step\"] == 0:\n                    self.scheduler.step()\n                #correct += (outputs[0].detach().cpu().numpy()==labels.to('cpu').numpy()).sum().item()\n                #pprint(correct)\n                total_loss += loss.item()\n            average_loss = total_loss / len(train_loader)\n            #average_accuracy = correct / len(train_loader)\n            #wandb.log({\"accuracy\": average_accuracy, \"loss\": average_loss})\n            wandb.log({\"loss\": average_loss, \"learning_rate\": self.scheduler.get_last_lr()})\n            #print(f'Epoch {epoch+1}/{wandb.config[\"epochs\"]} - Average Loss: {average_loss:.4f} - Average accuracy {average_accuracy:.4f}')\n            print(f'Epoch {epoch+1}/{wandb.config[\"epochs\"]} - Average Loss: {average_loss:.4f}')\n\n        print(\"Training complete!\")\n\n    def validate(self, dataset: CustomDataset) -> tp.Dict[str, tp.Iterable]:\n        \"\"\"\n        takes a trained model and runs it on validation data.\n        Returns a dict with the keys \"valid_labels\" and \"valid_preds\" and corresponding values.\n        \"\"\"\n        \n        dataloader = DataLoader(dataset, batch_size=8, shuffle=False)\n        \n        self.model.to(self.device)\n        self.model.eval()\n        \n        valid_preds, valid_labels = [], []\n\n        for batch in dataloader:\n\n            b_input_ids = batch[\"input_ids\"].to(self.device)\n            b_input_mask = batch[\"attention_mask\"].to(self.device)\n            b_labels = batch[\"label\"].to(self.device)\n\n            with torch.no_grad():\n                logits = self.model(input_ids=b_input_ids, attention_mask=b_input_mask)\n\n            logits = logits[0].detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n\n            batch_preds = np.argmax(logits, axis=1)\n            batch_labels = np.concatenate(label_ids.reshape(-1,1))\n            valid_preds.extend(batch_preds)\n            valid_labels.extend(batch_labels)\n\n        return valid_labels, valid_preds\n\n    def compute_metrics_report(\n        self, labels: tp.Iterable, predictions: tp.Iterable\n    ) -> tp.Any:\n        \"\"\"\n        Computes classification metric (or several metrcis) for given task.\n        \"\"\"\n        \n        recall = recall_score(labels, predictions)\n        precision = precision_score(labels, tpredictions)\n        f1_score = f1_score(labels, predictions)\n\n        results = {\n            'recall': recall,\n            'precision': precision,\n            'f1': f1_score\n        }\n        return results\n\n    def save_model(self, dst_path: str) -> None:\n        \"\"\"\n        Saves model to dst_path. Be careful to check if a model is on DataParallel state.\n        If it is, one needs to process it accordingly.\n        \"\"\"\n        if isinstance(self.model, nn.DataParallel):\n            torch.save(model.module.state_dict(), PATH)\n        else:\n            torch.save(self.model, dst_path)\n\n    def run_experiment(self):\n        \"\"\"\n        Main entrypoint.\n        Runs the flow from loading data to computing metrics.\n        \"\"\"\n        wandb.login(key = 'ed5e812f0a2ec095a0e7b29e696ac3f9655e62ed')\n        \n        train_df = self.load_data(filename = self.dataset_name, split = 'train')\n   \n        train_dataset = CustomDataset(\n            texts=train_df[\"text\"].tolist(),\n            labels=train_df[\"label\"].tolist(),\n            tokenizer=self.tokenizer,\n            max_length=512,\n        )\n        # Соберем общий конфиг для wandb\n        wandb_config = {\n            \"epochs\":5, \n            \"lr\": 1e-3, \n            \"weight_decay\": 5e-4, \n            \"learning_rate_decay_step\": 2, \n            \"learning_rate_decay_factor\": 0.9\n            ,}\n        \n        # Init для wandb\n        wandb.init(project=\"hw-07-transformers\", \n                   notes=\"Dataset Name \" + self.dataset_name, \n                   tags=[\"baseline\", \"transformer\", \"distilbert-base\"], \n                   config=wandb_config,\n                  )\n        # Для оптимайзера - срез из конфига по wandb        \n        optimizer_param_list = ['lr', 'weight_decay']\n        \n        optimizer_params = {k: wandb_config[k] for k in optimizer_param_list}\n        self.configure_optimizer(optimizer = AdamW(self.model.parameters()), params = optimizer_params)\n        \n        # Выбираем экспоненциальный шедулер\n        self.configure_scheduler(scheduler = ExponentialLR(optimizer=self.optimizer, gamma=wandb.config[\"learning_rate_decay_factor\"], last_epoch=-1))\n        \n        self.apply_data_parallel()\n        \n        self.train(train_dataset)\n        \n        test_df = self.load_data(filename = self.dataset_name, split = 'test')\n        \n        test_dataset = CustomDataset(\n            texts=test_df[\"text\"].tolist(),\n            labels=test_df[\"label\"].tolist(),\n            tokenizer=self.tokenizer,\n            max_length=512,\n        )\n        \n        \n        valid_labels, valid_preds = self.validate(test_dataset)\n        \n        valid_scores = self.compute_metrics_report(valid_labels, valid_preds)\n        \n        self.save_model(dst_path = './distilbert-base-uncased_baseline.pt')\n        \n        pprint(valid_scores)\n        \n\nif __name__ == \"__main__\":\n    \"\"\"run experiment\"\"\"\n    model_trainer = ModelTrainer(model_name = \"distilbert-base-uncased\",\n                                 dataset_name = \"imdb\",\n                                 sample = 2000,\n                                )\n    model_trainer.run_experiment()","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:31:03.772101Z","iopub.execute_input":"2024-05-20T07:31:03.772655Z","iopub.status.idle":"2024-05-20T07:44:29.185687Z","shell.execute_reply.started":"2024-05-20T07:31:03.772618Z","shell.execute_reply":"2024-05-20T07:44:29.184091Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5deeb707594c433eae5e9dc8d75b81aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f43d02452a34757b8d824dae94d8385"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b97721542be487485234f7e7863e210"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15832e549d9e46a9a3d8fc3f5acb2565"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64127f4d1dac4eacbdf873041c8962c6"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/7.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8153fa05309449e4b1574cf70860ef2a"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 21.0M/21.0M [00:00<00:00, 79.3MB/s]\nDownloading data: 100%|██████████| 20.5M/20.5M [00:00<00:00, 54.5MB/s]\nDownloading data: 100%|██████████| 42.0M/42.0M [00:00<00:00, 126MB/s] \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc2134ef4cdb486f869e7e70225b1ad9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e990980dc2f94a4eb7fbd532f566569f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10b6eae18f544342b3e13b6e198f378b"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrei-simkin\u001b[0m (\u001b[33man4sim\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240520_073120-4sy2zdp2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/an4sim/hw-07-transformers/runs/4sy2zdp2' target=\"_blank\">sunny-plasma-30</a></strong> to <a href='https://wandb.ai/an4sim/hw-07-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/an4sim/hw-07-transformers' target=\"_blank\">https://wandb.ai/an4sim/hw-07-transformers</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/an4sim/hw-07-transformers/runs/4sy2zdp2' target=\"_blank\">https://wandb.ai/an4sim/hw-07-transformers/runs/4sy2zdp2</a>"},"metadata":{}},{"name":"stderr","text":" 20%|██        | 1/5 [02:22<09:29, 142.37s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5 - Average Loss: 0.6933\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 2/5 [04:45<07:08, 142.69s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 2/5 - Average Loss: 0.6945\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 3/5 [07:08<04:45, 142.82s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 3/5 - Average Loss: 0.6948\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 4/5 [09:31<02:22, 142.98s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 4/5 - Average Loss: 0.6922\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [11:55<00:00, 143.00s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 5/5 - Average Loss: 0.6946\nTraining complete!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 278\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"run experiment\"\"\"\u001b[39;00m\n\u001b[1;32m    274\u001b[0m model_trainer \u001b[38;5;241m=\u001b[39m ModelTrainer(model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    275\u001b[0m                              dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimdb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    276\u001b[0m                              sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m,\n\u001b[1;32m    277\u001b[0m                             )\n\u001b[0;32m--> 278\u001b[0m \u001b[43mmodel_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[3], line 265\u001b[0m, in \u001b[0;36mModelTrainer.run_experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m CustomDataset(\n\u001b[1;32m    256\u001b[0m     texts\u001b[38;5;241m=\u001b[39mtest_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    257\u001b[0m     labels\u001b[38;5;241m=\u001b[39mtest_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    258\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer,\n\u001b[1;32m    259\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m    260\u001b[0m )\n\u001b[1;32m    263\u001b[0m valid_labels, valid_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate(test_dataset)\n\u001b[0;32m--> 265\u001b[0m valid_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_preds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(dst_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./distilbert-base-uncased_baseline.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    269\u001b[0m pprint(valid_scores)\n","Cell \u001b[0;32mIn[3], line 189\u001b[0m, in \u001b[0;36mModelTrainer.compute_metrics_report\u001b[0;34m(self, labels, predictions)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_metrics_report\u001b[39m(\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m, labels: tp\u001b[38;5;241m.\u001b[39mIterable, predictions: tp\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    184\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tp\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m    185\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    Computes classification metric (or several metrcis) for given task.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m     recall \u001b[38;5;241m=\u001b[39m recall_score(\u001b[43mtrue_labels\u001b[49m, true_predictions)\n\u001b[1;32m    190\u001b[0m     precision \u001b[38;5;241m=\u001b[39m precision_score(true_labels, true_predictions)\n\u001b[1;32m    191\u001b[0m     f1_score \u001b[38;5;241m=\u001b[39m f1_score(true_labels, true_predictions)\n","\u001b[0;31mNameError\u001b[0m: name 'true_labels' is not defined"],"ename":"NameError","evalue":"name 'true_labels' is not defined","output_type":"error"}]}]}